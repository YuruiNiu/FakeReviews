{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy : We started experimenting with TOP-10 categories (based on frequency of reviews) for simplicity. We finetuned these categories on a sample set.    \n",
    "Categories consumed : [All_Beauty_5.json.gz, Automotive_5.json.gz, Gift_Cards_5.json.gz, Magazine_Subscriptions_5.json.gz, AMAZON_FASHION_5.json.gz, CDs_and_Vinyl_5.json.gz, Grocery_and_Gourmet_Food_5.json.gz, Musical_Instruments_5.json.gz, Appliances_5.json.gz, Cell_Phones_and_Accessories_5.json.gz, Industrial_and_Scientific_5.json.gz, Office_Products_5.json.gz, Arts_Crafts_and_Sewing_5.json.gz, Digital_Music_5.json.gz, Luxury_Beauty_5.json.gz, Patio_Lawn_and_Garden_5.json.gz]   \n",
    "Train Rows : ~144k  \n",
    "Validation Rows : ~16k      \n",
    "Model : ULMFit *CHANDRA: please explain briefly what this model is about and how it works*   \n",
    "Performance *CHANDRA: please explain briefly the performance metrics, how they work, and why they were chosen* :  \n",
    "\n",
    "            |epoch   |  train_loss   |  valid_loss   | accuracy    |   perplexity    |      time    |\n",
    "            | ------ | ------------- | ------------- | ----------- | --------------  | ------------ |\n",
    "            |    0   |  4.091950     |  3.965241     | 0.294048    |  \t52.732975    |  1:27:53   |\n",
    "            |    1   |  4.138435     |  4.004159     | 0.290700    |  \t54.825722    |  1:50:32   |\n",
    "            |    2   |  4.075377     |  3.994715     | 0.291748    |  \t54.310360    |  2:00:35   |\n",
    "            |    3   |  4.099702     |  3.969203     | 0.294860    |  \t52.942307    |  1:47:00   |\n",
    "            |    4   |  3.998508     |  3.940119     | 0.298114    |  \t51.424698    |  1:47:01   |\n",
    "            |    5   |  4.016881     |  3.898405     | 0.302949    |  \t49.323696    |  1:47:03   |\n",
    "            |    6   |  3.918993     |  3.859989     | 0.307038    |  \t47.464836    |  1:47:01   |\n",
    "            |    7   |  3.890229     |  3.825045     | 0.311247    |  \t45.834869    |  1:47:17   |\n",
    "            |    8   |  3.837510     |  3.801839     | 0.314293    |  \t44.783470    |  1:52:52   |\n",
    "            |    9   |  3.823071     |  3.796320     | 0.315118    |  \t44.537006    |  1:48:25   |\n",
    "Weights: finetuned-amazon-reviews-sample.pth *CHANDRA: what's the interpretation of the numbers in the table? write a short caption telling the reader what they should be paying attention to and why*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy : Take below(to start, later all) categories, finetune on sample set.    \n",
    "Categories consumed : [All_Beauty_5.json.gz, Automotive_5.json.gz, Gift_Cards_5.json.gz, Magazine_Subscriptions_5.json.gz, AMAZON_FASHION_5.json.gz, CDs_and_Vinyl_5.json.gz, Grocery_and_Gourmet_Food_5.json.gz, Musical_Instruments_5.json.gz, Appliances_5.json.gz, Cell_Phones_and_Accessories_5.json.gz, Industrial_and_Scientific_5.json.gz, Office_Products_5.json.gz, Arts_Crafts_and_Sewing_5.json.gz, Digital_Music_5.json.gz, Luxury_Beauty_5.json.gz, Patio_Lawn_and_Garden_5.json.gz]   \n",
    "Train Rows : ~ 40k  \n",
    "Validation Rows : ~10k  \n",
    "Model : GPT-2 *CHANDRA: again, briefly explain this model and why it was chosen*  \n",
    "Performance:   \n",
    "\n",
    "            |  epoch  | train_loss  |  valid_loss  |  perplexity |  time    |\n",
    "            |  -----  | ----------  |  ----------  |  ---------- | ----     |\n",
    "            |    0    |   3.772770  |  3.672615    |  39.354694  |   1:28:52|\n",
    "            \n",
    "Weights: gpt2-finetuned-amazon-reviews-sample-1cycle.pth  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-14 Categories\n",
    "Books \t5-core (27,164,983 reviews) \tratings only (51,311,621 ratings)  Y   \n",
    "Clothing, Shoes and Jewelry \t5-core (11,285,464 reviews) \tratings only (32,292,099 ratings)  X   \n",
    "Home and Kitchen \t5-core (6,898,955 reviews) \tratings only (21,928,568 ratings)  X   \n",
    "Electronics \t5-core (6,739,590 reviews) \tratings only (20,994,353 ratings)  X   \n",
    "Movies and TV \t5-core (3,410,019 reviews) \tratings only (8,765,568 ratings)  Y   \n",
    "Sports and Outdoors \t5-core (2,839,940 reviews) \tratings only (12,980,837 ratings)  Y   \n",
    "Kindle Store \t5-core (2,222,983 reviews) \tratings only (5,722,988 ratings) Y   \n",
    "Pet Supplies \t5-core (2,098,325 reviews) \tratings only (6,542,483 ratings) Y   \n",
    "Tools and Home Improvement \t5-core (2,070,831 reviews) \tratings only (9,015,203 ratings)  Y   \n",
    "Toys and Games \t5-core (1,828,971 reviews) \tratings only (8,201,231 ratings)  Y   \n",
    "\n",
    "Automotive \t5-core (1,711,519 reviews) \tratings only (7,990,166 ratings)    \n",
    "CDs and Vinyl \t5-core (1,443,755 reviews) \tratings only (4,543,369 ratings)   \n",
    "Grocery and Gourmet Food \t5-core (1,143,860 reviews) \tratings only (5,074,160 ratings)   \n",
    "Cell Phones and Accessories \t5-core (1,128,437 reviews) \tratings only (10,063,255 ratings)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observations as on March 6th, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training together with different categories fine tuned GPT-2 model with different sampling algorithms are giving human type text generation. *CHANDRA: any examples that illustrate this? (please include)* In contrast, the finetuned ULMFit is certainly lacking in the quality and context of a category. *CHANDRA: please give examples*  \n",
    "2. Initial results can be seen in individual notebooks.  \n",
    "3. These models can be shared over drive or storage if required.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps as on March 6th, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Will be looking into ULMFit a bit deeper from modeling standpoint. *CHANDRA: OK, good*  \n",
    "2. Will be picking individual categories from dataset starting from least to most and train ULMFit and GPT-2 models per category level. *CHANDRA: OK, good. I guess after that you will be able to tell which approach is better - category-level or global training* \n",
    "3. Will be sharing intial insights. *CHANDRA: looking forward :)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
